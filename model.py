# Reduce terminal logging verbosity
import os
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"

# Import libraries
import tensorflow as tf
from tensorflow.python import keras, data
from tensorflow.python.keras import layers, losses
from keras import utils
from keras.layers import Rescaling
from keras.callbacks import History
import numpy as np
from PIL import Image
from random import Random
import pathlib
import matplotlib.pyplot as plt

# Training Images Location Definitions
dataPath = "../Generated Images"

# Class container for model
class CNN(tf.Module):
	def __init__(self, imgDim: tuple = (512, 512, 3)):
		self.model = keras.Sequential(
			[
				layers.Conv2D(8, (4, 4), padding = 'same', input_shape = imgDim, activation = 'relu'),
				Rescaling(1. / 255),
				layers.MaxPooling2D(pool_size = (2, 2)),
				layers.Conv2D(16, (4, 4), padding = 'same', activation = 'relu'),
				layers.MaxPooling2D(pool_size = (2, 2)),
				layers.Conv2D(8, (4, 4), padding = 'same', activation = 'relu'),
				layers.MaxPooling2D(pool_size = (2, 2)),
				layers.Dropout(0.2),
				layers.Flatten(),
				layers.Dense(64, activation = "relu"),
				layers.Dense(2)
			]
		)
		self.model.compile(
			optimizer = "adam",
			loss = losses.SparseCategoricalCrossentropy(from_logits = True)
		)

		self.trainData = None
		self.testData = None
		self.history = None
	
	def train(self, seed: int = 1542, epochs: int = 10):
		# Configuring datasets for better loading performance
		tuner = data.AUTOTUNE
		self.trainData = self.trainData.cache().shuffle(seed).prefetch(buffer_size = tuner)
		self.testData = self.testData.cache().prefetch(buffer_size = tuner)

		# Training CNN Model
		return self.model.fit(self.trainData,
			validation_data = self.testData,
			epochs = epochs)

	def trainSummary(self):
		loss = self.history.history['loss']
		val_loss = self.history.history['val_loss']

		epochs_range = self.history.epoch

		plt.figure(figsize=(8, 8))
		plt.plot(epochs_range, loss, label='Training Loss')
		plt.plot(epochs_range, val_loss, label='Validation Loss')
		plt.legend(loc='upper right')
		plt.title('Training and Validation Loss')
		#plt.show()

	@tf.function
	def loadData(self, trainTestSplit: float = 0.35, seed: int = 1574):
		dataDir = pathlib.Path(dataPath)
		batchSize = 32

		# Creating dataset loaders
		trainData = utils.image_dataset_from_directory(dataDir,
						      validation_split = trainTestSplit,
							  subset = "training",
							  seed = seed,
							  image_size = (512, 512),
							  batch_size = batchSize)

		testData = utils.image_dataset_from_directory(dataDir,
						     validation_split = trainTestSplit,
							 subset = "validation",
							 seed = seed,
							 image_size = (512, 512),
							 batch_size = batchSize)

		return trainData, testData

	def rawPredict(self, exePath: str = "test.exe"):
		
		return []

	def saveModel(self, modelFile: str = ".model"):
		self.model.save(modelFile)

	def loadModel(self, modelFile: str = ".model"):
		self.model.load_weights(modelFile)

	def debugInfo(self):
		print(self.model)
		for layer in self.model.layers:
			print(layer)
		
		self.model.summary()
		print(self.model.get_weights())

model = CNN()
#model.trainData, model.testData = model.loadData()
#model.history = model.train(epochs = 5)
#model.trainSummary()
#model.saveModel()
model.loadModel()
model.debugInfo()
